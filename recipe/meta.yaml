{% set version = "1.12.1" %}
{% set commit = "664058fa83f1d8eede5d66418abff6e20bd76ca8" %}

package:
  name: pytorch
  version: {{ version }}

source:
  # for local testing use a tarball including submodules
  git_url: https://github.com/pytorch/pytorch.git
  git_tag: {{ commit }}
  #path: ../../../pytorch
  patches:
    # It is unclear that upstream will allow us to integrate the shared linker
    # path below until their Intel compiler issues are resolved.
    - patches/remove_shared_linker_flag_override.patch
    # https://github.com/pytorch/pytorch/pull/49281
    - patches/fix_std_stdint.patch
    - patches/fix_dispatch_apply_auto.patch
    - patches/cpp_extension.patch
    # Fixes invalid use of a preprocessor macro meant to be used on char
    # literals, but used on a variable instead.
    # - patches/fix-invalid-cpp-use-unit8c.patch  # [osx] # Code moved to oneDNN and fixed.
    # Some third-party modules seem to expect TARGET_OS_OSX to be set, whereas
    # the actual define in use nowadays seems to be TARGET_OS_MAC.
    - patches/fix-target-os-osx-macro.patch  # [osx]
    # Fixes compiler crash on (potentially) invalid use of #pragma omp critical
    # See also https://github.com/pytorch/pytorch/pull/65655
    # - patches/parallel-for-not-backed-by-omp.patch  # [osx] # Patch upstreamed
    # Fixes use of stdout without iostream included.
    # - patches/remove-unused-dump-methods.patch # Patch upstreamed
    # Fixes a problem with altivec optimizations compilation.
    # - patches/add-dummy-bfloat16-impl.patch # Patch upstreamed
    # PyTorch (and most submodules) search for Python differently than gtest,
    # which ends up using (and wanting to link to) the system Python in some
    # constellations, which messes up the build.
    - patches/gtest-find-pyinterp.patch
    # gtest turns on -Werror breaking the build.
    - patches/gtest-no-werror.patch
    # Fix a compiler check to handle absolute paths.
    - patches/handle-abs-compiler-path.patch
    # Fix little problems with the test suite.
    - patches/fix-flaky-tests.patch
    # Fixes usage of non-standard ssize_t.
    # - patches/remove-non-standard-ssize_t.patch  # [win] #upstreamed

build:
  number: 0
  # Automated s390x builds fail. The exact reason is unknown but probably due
  # to resource constraints (the build is very memory intensive). Manual builds
  # may or may not go through, your mileage may vary.
  skip: True  # [py<37]
  string: cuda{{ cudatoolkit | replace('.', '') }}py{{ CONDA_PY }}h{{PKG_HASH}}_{{ PKG_BUILDNUM }}  # [pytorch_variant == "gpu"]
  string: cpu_py{{ CONDA_PY }}h{{PKG_HASH}}_{{ PKG_BUILDNUM }}                                      # [pytorch_variant == "cpu"]
  detect_binary_files_with_prefix: False
  missing_dso_whitelist:
    # It is not clear, why conda-build cannot figure these out:
    - "**/ld64.so.*"              # [linux]
    - "**/libc10.so"              # [linux]
    - "**/libshm.so"              # [linux]
    - "**/libtorch.so"            # [linux]
    - "**/libtorch_cpu.so"        # [linux]
    - "**/libtorch_python.so"     # [linux]
    - "**/libiomp5.so"            # [linux]
    - "**/libc10.dylib"           # [osx]
    - "**/libshm.dylib"           # [osx]
    - "**/libtorch.dylib"         # [osx]
    - "**/libtorch_cpu.dylib"     # [osx]
    - "**/libtorch_python.dylib"  # [osx]
    - "**/libiomp5.dylib"         # [osx]
    - "**/asmjit.dll"             # [win]
    - "**/c10.dll"                # [win]
    - "**/fbgemm.dll"             # [win]
    - "**/shm.dll"                # [win]
    - "**/torch_cpu.dll"          # [win]
    - "**/torch_python.dll"       # [win]

requirements:
  # WARNING:
  #
  # Make sure host and build Python are the same version. Unfortunately,
  # PyTorch's build system (or some of the submodules) seems to mix up the
  # Python interpreters.
  #
  build:
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - cmake
    - make                            # [unix]
    - git                             # [not win]
    - patch                           # [not win]
    - m2-git                          # [win]
    - m2-patch                        # [win]
    - python ={{PY_VER}}
    - ninja
  host:
    # GPU requirements
    - cudatoolkit {{ cudatoolkit }}*  # [pytorch_variant == "gpu"]
    - cudnn {{ cudnn }}*              # [pytorch_variant == "gpu"]
    - magma                           # [pytorch_variant == "gpu"]
    # OpenBLAS or MKL
    - mkl-devel {{ mkl }}.*           # [blas_impl == "mkl"]
    - mkl {{ mkl }}.*                 # [blas_impl == "mkl"]
    - openblas                        # [blas_impl == "openblas"]
    # OpenMP
    - intel-openmp                    # [(osx or win) and x86]
    - llvm-openmp                     # [osx and arm64]
    # Other requirements
    - cffi
    - future
    - libuv                           # [win]
    # Pinnings as per pytorch/.circleci/docker/common/install_conda.sh,
    # except for python 3.8 because we don't have the version specified
    - numpy =1.21.2 # [py>=310]
    - numpy =1.19.2 # [py<=39]
    - pip
    - pkg-config                      # [unix]
    - python
    - pyyaml
    - requests
    # CF: PyTorch relies on features that were removed in later versions.
    - setuptools <59.6
    - typing-extensions
    - wheel
  run:
    # OpenBLAS or MKL
    - mkl {{ mkl }}.*                 # [blas_impl == "mkl"]
    - libopenblas                     # [blas_impl == "openblas"]
    # OpenMP
    - intel-openmp                    # [(osx or win) and x86]
    - llvm-openmp                     # [osx and arm64]
    # GPU requirements
    - {{ pin_compatible('cudatoolkit', max_pin='x.x') }}  # [pytorch_variant == "gpu"]
    - {{ pin_compatible('cudnn') }}                       # [pytorch_variant == "gpu"]
    # other requirements
    - cffi
    # CF: pip check may fail if future is not installed
    - future
    # CF: needed to load C++ extensions
    - ninja
    - {{ pin_compatible('numpy') }}
    - python
    - typing-extensions
    # ppc64le compilers still need to be updated to use `_openmp_mutex`.
    - _openmp_mutex                   # [linux and not ppc64le]
    - pyyaml

test:
  requires:
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - expecttest
    - hypothesis
    - mock  # [linux]
    - pip
    - psutil
    - pytest
    - scipy
    - setuptools
    - six
    - tabulate
  imports:
    - torch
  source_files:
    - test/
  commands:
    # We seem to have individual platform-specific test failures or flaky
    # tests, but the majority of tests passes.
    - python ./test/run_test.py --core || true
    # Run pip check so as to ensure that all pytorch packages are installed
    # https://github.com/conda-forge/pytorch-cpu-feedstock/issues/24
    - pip check

about:
  home: https://pytorch.org/
  license: BSD-3-Clause
  license_family: BSD
  license_file: LICENSE
  summary: PyTorch is an optimized tensor library for deep learning using GPUs and CPUs.
  dev_url: https://github.com/pytorch/pytorch
  doc_url: https://pytorch.org/docs/1.10/index.html

extra:
  recipe-maintainers:
    - tobijk
