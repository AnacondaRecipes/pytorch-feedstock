{% set version = "1.6.0" %}
{% set commit = "b31f58de6fa8bbda5353b3c77d9be4914399724d" %}

package:
  name: pytorch-{{ pytorch_variant }}
  version: {{ version }}

source:
  # for local testing use a tarball including submodules
  git_url: https://github.com/pytorch/pytorch.git
  git_tag: {{ commit }}
  patches:
    # https://github.com/pytorch/pytorch/pull/49281
    - fix_std_stdint.patch
    # cpp_extension patch does not apply cleanly on master
    # we should try to upstream again on the next version
    - cpp_extension.patch
    # It is unclear that upstream will allow us to integrate the 
    # shared linker path bellow until their intel compiler issues
    # are resolved.
    - remove_shared_linker_flag_override.patch
    - nccl_socket.patch
    - fix_dispatch_apply_auto.patch
    - fix_map_anonymous.patch

build:
  number: 1
  string: cuda{{ cudatoolkit | replace('.', '') }}py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [pytorch_variant == "gpu"]
  string: cpu_py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}                                      # [pytorch_variant == "cpu"]
  detect_binary_files_with_prefix: False

requirements:
  build:
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    # Dec 2020: it seems that git is broken on windows, so we use m2-git
    - patch     # [not win]
    - m2-patch  # [win]
    - git       # [not win]
    - m2-git    # [win]
  host:
    # For some reason cmake and ninja need to be installed
    # alongside python in the host
    # https://github.com/conda-forge/pytorch-cpu-feedstock/pull/21#discussion_r541397252
    - cmake
    - ninja
    - git       # [not win]
    - m2-git    # [win]
    # GPU requirements
    #- cudatoolkit {{ cudatoolkit }}*  # [pytorch_variant == "gpu"]
    #- cudnn {{ cudnn }}*              # [pytorch_variant == "gpu"]
    #- magma                           # [pytorch_variant == "gpu"]
    # other requirements
    - python
    - numpy
    - pip
    - setuptools
    - pyyaml
    - requests
    - future
    - six
    - cffi
    - mkl-devel {{ mkl }}
    - mkl {{ mkl }}
    - libblas * *_mkl
    - typing
    - libuv       # [unix]
    - pkg-config  # [unix]
    #- intel-openmp  # [osx]
  run:
    - mkl {{ mkl }}
    - libblas * *_mkl
    #- intel-openmp   # [osx]
    - llvm-openmp    # [osx]
    #- _pytorch_select ==0.1             # [pytorch_variant == "cpu"]
    #- _pytorch_select ==0.2             # [pytorch_variant == "gpu"]
    # GPU requirements
    #- {{ pin_compatible('cudatoolkit', max_pin='x.x') }}  # [pytorch_variant == "gpu"]
    #- {{ pin_compatible('cudnn') }}                       # [pytorch_variant == "gpu"]
    # other requirements
    - python
    - {{ pin_compatible('numpy') }}
    - cffi
    # if future isn't installed on python 3, `pip check` can give
    # the user an error
    - future
    - typing  # [py2k]

test:
  requires:
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - setuptools
    - hypothesis
    - pytest
    - tabulate
    - pydot
    - mock  # [linux]
  imports:
    - torch
  source_files:
    - test
  commands:
    - OMP_NUM_THREADS=4 python ./test/run_test.py || true  # [not win]
    - python ./test/run_test.py  # [win]
    # Run pip check so as to ensure that all pytorch packages are installed
    # https://github.com/conda-forge/pytorch-cpu-feedstock/issues/24
    - pip check

about:
  home: https://pytorch.org/
  license: BSD-3-Clause
  license_family: BSD
  license_file: LICENSE
  summary: PyTorch is an optimized tensor library for deep learning using GPUs and CPUs.

extra:
  recipe-maintainers:
    - hmaarrfk
    - sodre
