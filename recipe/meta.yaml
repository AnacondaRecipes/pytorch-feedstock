{% set version = "1.8.1" %}
{% set commit = "v" + version %}

package:
  name: pytorch
  version: {{ version }}

source:
  # for local testing use a tarball including submodules
  git_url: https://github.com/pytorch/pytorch.git
  git_tag: {{ commit }}
  patches:
    #- nccl_socket.patch
    # It is unclear that upstream will allow us to integrate the shared linker
    # path below until their Intel compiler issues are resolved.
    - remove_shared_linker_flag_override.patch
    # https://github.com/pytorch/pytorch/pull/49281
    - fix_std_stdint.patch
    - fix_dispatch_apply_auto.patch
    #- fix_map_anonymous.patch
    - cpp_extension.patch
    - fix_msvc_build_issue.patch    # [win]
    # https://github.com/pytorch/pytorch/pull/49647
    - fix_blas_lapack.patch
    # - fix_c10_export_gcc.patch
    # - do_not_check_clock_realtime.patch

build:
  number: 1
  string: cuda{{ cudatoolkit | replace('.', '') }}py{{ CONDA_PY }}h{{PKG_HASH}}_{{ PKG_BUILDNUM }}  # [pytorch_variant == "gpu"]
  string: cpu_py{{ CONDA_PY }}h{{PKG_HASH}}_{{ PKG_BUILDNUM }}                                      # [pytorch_variant == "cpu"]
  detect_binary_files_with_prefix: False
  skip: True  # [py>39]
  missing_dso_whitelist:
    - "**/ld64.so.*"    # [linux]

requirements:
  build:
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - patch     # [not win]
    - m2-patch  # [win]
    - git       # [not win]
    - m2-git    # [win]
    - cmake
    - make      # [unix]
  host:
    # GPU requirements
    - cudatoolkit {{ cudatoolkit }}*  # [pytorch_variant == "gpu"]
    - cudnn {{ cudnn }}*              # [pytorch_variant == "gpu"]
    - magma                           # [pytorch_variant == "gpu"]
    # other requirements
    - python
    - numpy-devel {{ numpy }}  # [not (osx and arm64) and py<=39]
    - numpy  {{ numpy }}       # [(osx and arm64) or py>39]
    - pip
    - setuptools
    - pyyaml
    - requests
    - future
    - six
    - cffi
    - mkl-devel {{ mkl }}   # [blas_impl == "mkl"]
    - mkl {{ mkl }}         # [blas_impl == "mkl"]
    - openblas              # [blas_impl == "openblas"]
    - typing                # [py2k]
    - typing_extensions
    - ninja
    # PyTorch builds its own vendored version of libuv, so no need to supply it
    #- libuv                 # [unix]
    - pkg-config  # [unix]
    - intel-openmp  # [osx and x86_64]
  run:
    - mkl {{ mkl }}     # [blas_impl == "mkl"]
    - libmklml          # [blas_impl == "mkl"]
    - libopenblas       # [blas_impl == "openblas"]
    - intel-openmp   # [osx]
    - llvm-openmp    # [osx]
    - _pytorch_select ==0.1             # [pytorch_variant == "cpu"]
    - _pytorch_select ==0.2             # [pytorch_variant == "gpu"]
    # GPU requirements
    - {{ pin_compatible('cudatoolkit', max_pin='x.x') }}  # [pytorch_variant == "gpu"]
    - {{ pin_compatible('cudnn') }}                       # [pytorch_variant == "gpu"]
    # other requirements
    - python
    - cffi
    - ninja
    - future  # [py2k]
    - typing  # [py2k]
    - typing-extensions
    # ppc64le compilers still need to be updated to use `_openmp_mutex`.
    - _openmp_mutex     # [linux and not ppc64le]

test:
  requires:
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - setuptools
    - hypothesis
    - pytest
    - tabulate
    - pydot
    - mock  # [linux]
    - pip
  imports:
    - torch
  source_files:
    - test
  commands:
    - OMP_NUM_THREADS=2 python ./test/run_test.py -v || true  # [not win]
    - python ./test/run_test.py -v  # [win]
    # Run pip check so as to ensure that all pytorch packages are installed
    # https://github.com/conda-forge/pytorch-cpu-feedstock/issues/24
    - pip check

about:
  home: https://pytorch.org/
  license: BSD-3-Clause
  license_family: BSD
  license_file: LICENSE
  summary: PyTorch is an optimized tensor library for deep learning using GPUs and CPUs.
